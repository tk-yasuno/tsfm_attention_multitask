# Hybrid Model v2.1 Enhancement Guide
ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«v2.1 æ”¹å–„ã‚¬ã‚¤ãƒ‰

## ğŸ“‹ Overview / æ¦‚è¦

v2.0ã‹ã‚‰v2.1ã¸ã®ä¸»è¦ãªæ”¹å–„ç‚¹ï¼š

### ğŸ¯ v2.0ã®èª²é¡Œ
- **ç·šå½¢çš„ãªäºˆæ¸¬**: LightGBMãƒ™ãƒ¼ã‚¹ã®äºˆæ¸¬ãŒç›´ç·šçš„ã§ã€ç¾å®Ÿã®ãµã‚‹ã¾ã„ã¨ä¹–é›¢
- **ç‰¹å¾´é‡ã®é™å®šçš„æ´»ç”¨**: 28æ¬¡å…ƒã®çµ±è¨ˆç‰¹å¾´é‡ãŒLightGBMã§ã®ã¿ä½¿ç”¨
- **ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ã¸ã®å¯¾å¿œä¸è¶³**: æ¨™æº–çš„ãªæå¤±é–¢æ•°ã§ã¯ç•°å¸¸ã‚¯ãƒ©ã‚¹ã®å­¦ç¿’ãŒä¸ååˆ†

### âœ¨ v2.1ã®æ”¹å–„
1. **éç·šå½¢äºˆæ¸¬ã®å®Ÿç¾**
   - éå»90æ—¥ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’2æ¬¡å¤šé …å¼ã§ãƒ¢ãƒ‡ãƒ«åŒ–
   - çµ±è¨ˆç‰¹å¾´é‡ã«ã‚ˆã‚‹äºˆæ¸¬èª¿æ•´
   - è¨­å‚™ç®¡ç†è€…ã«ç›´æ„Ÿçš„ãªå»¶é•·ç·šäºˆæ¸¬

2. **ç‰¹å¾´é‡ã®å¤šæ¬¡å…ƒæ´»ç”¨**
   - TinyTimeMixeråŸ‹ã‚è¾¼ã¿ï¼ˆ64æ¬¡å…ƒï¼‰+ çµ±è¨ˆç‰¹å¾´é‡ï¼ˆ28æ¬¡å…ƒï¼‰= 92æ¬¡å…ƒ
   - Feature Fusion Layerã§çµ±åˆ
   - Multi-Layer Classifierã§éç·šå½¢å¤‰æ›

3. **LoRA Fine-Tuning**
   - TinyTimeMixerã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§å¾®èª¿æ•´
   - LoRAãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã¿è¨“ç·´ï¼ˆåŠ¹ç‡çš„ãªè»¢ç§»å­¦ç¿’ï¼‰
   - äº‹å‰å­¦ç¿’ã®çŸ¥è­˜ã‚’ä¿æŒã—ã¤ã¤ãƒ‰ãƒ¡ã‚¤ãƒ³é©å¿œ

4. **Focal Loss (beta=3)**
   - ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ã«å¯¾å¿œã—ãŸæå¤±é–¢æ•°
   - é›£ã—ã„ã‚µãƒ³ãƒ—ãƒ«ã«é‡ç‚¹çš„ã«å­¦ç¿’
   - ç•°å¸¸ã‚¯ãƒ©ã‚¹ã®æ¤œå‡ºç²¾åº¦å‘ä¸Š

---

## ğŸ—ï¸ Architecture / ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```
[Input: æ™‚ç³»åˆ— 90æ—¥] â”€â”€â”€â”€â”
                        â”‚
                        â”œâ”€â”€> TinyTimeMixer Encoder (LoRA Fine-tuned)
                        â”‚         â†“
                        â”‚    [Embeddings: 64d]
                        â”‚         â”‚
[Input: çµ±è¨ˆç‰¹å¾´ 28d] â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€> Feature Fusion Layer
                                       â†“
                                  [Fused: 92d]
                                       â†“
                              Multi-Layer Classifier
                           (128d â†’ 64d â†’ 1d + Sigmoid)
                                       â†“
                                  [ç•°å¸¸ç¢ºç‡]
                                       â†“
                              Focal Loss (gamma=3)
```

### ä¸»è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ

#### 1. TinyTimeMixer Encoder (LoRA Fine-tuned)
```python
# LoRAãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã¿è¨“ç·´å¯èƒ½
for param in encoder.parameters():
    param.requires_grad = False

for name, param in encoder.named_parameters():
    if 'lora' in name.lower():
        param.requires_grad = True
```

ç‰¹å¾´:
- äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã¯å›ºå®š
- LoRAä½ãƒ©ãƒ³ã‚¯è¡Œåˆ—ã®ã¿æ›´æ–°
- åŠ¹ç‡çš„ãªå¾®èª¿æ•´ï¼ˆè¨“ç·´ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ ~22%ï¼‰

#### 2. Feature Fusion + Classification
```python
fusion_layer = nn.Sequential(
    nn.Linear(92, 128),      # 64 embeddings + 28 stats â†’ 128
    nn.LayerNorm(128),
    nn.ReLU(),
    nn.Dropout(0.3),
    
    nn.Linear(128, 64),
    nn.LayerNorm(64),
    nn.ReLU(),
    nn.Dropout(0.3),
    
    nn.Linear(64, 1),
    nn.Sigmoid()
)
```

ç‰¹å¾´:
- æ·±ã„éç·šå½¢å¤‰æ›
- Layer Normalizationã§å®‰å®šåŒ–
- Dropoutã§éå­¦ç¿’é˜²æ­¢

#### 3. Focal Loss
```python
class FocalLoss(nn.Module):
    def __init__(self, alpha=0.25, gamma=3.0):
        # alpha: positive classã®é‡ã¿
        # gamma: focusing parameterï¼ˆé›£ã—ã„ã‚µãƒ³ãƒ—ãƒ«ã¸ã®é‡ç‚¹åº¦ï¼‰
    
    def forward(self, inputs, targets):
        bce_loss = F.binary_cross_entropy(inputs, targets, reduction='none')
        p_t = inputs * targets + (1 - inputs) * (1 - targets)
        focal_weight = (1 - p_t) ** gamma
        alpha_t = alpha * targets + (1 - alpha) * (1 - targets)
        focal_loss = alpha_t * focal_weight * bce_loss
        return focal_loss.mean()
```

åŠ¹æœ:
- ç°¡å˜ãªã‚µãƒ³ãƒ—ãƒ«ï¼ˆé«˜ç¢ºä¿¡åº¦ï¼‰ã®æå¤±ã‚’æŠ‘åˆ¶: $(1 - p_t)^3$
- é›£ã—ã„ã‚µãƒ³ãƒ—ãƒ«ï¼ˆä½ç¢ºä¿¡åº¦ï¼‰ã®æå¤±ã‚’å¢—å¹…
- ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ã®è‡ªå‹•èª¿æ•´

---

## ğŸš€ Usage / ä½¿ã„æ–¹

### 1. ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°

```bash
# venvç’°å¢ƒã‚’ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ãƒˆ
.\venv\Scripts\Activate.ps1

# v2.1ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
python train_hybrid_model_v2_1.py
```

ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰:
- **Epochs**: 15ï¼ˆæ—©æœŸåœæ­¢ã‚ã‚Šï¼‰
- **Batch Size**: 128
- **Learning Rate**: 5e-5
- **Optimizer**: AdamW (weight_decay=0.01)
- **Scheduler**: CosineAnnealingLR
- **Focal Loss**: alpha=auto, gamma=3.0

å‡ºåŠ›:
```
models/hybrid_model_v2.1/
â”œâ”€â”€ pytorch_model_30d.pt    # 30æ—¥ãƒ›ãƒ©ã‚¤ã‚ºãƒ³ãƒ¢ãƒ‡ãƒ«
â”œâ”€â”€ pytorch_model_60d.pt    # 60æ—¥ãƒ›ãƒ©ã‚¤ã‚ºãƒ³ãƒ¢ãƒ‡ãƒ«
â”œâ”€â”€ pytorch_model_90d.pt    # 90æ—¥ãƒ›ãƒ©ã‚¤ã‚ºãƒ³ãƒ¢ãƒ‡ãƒ«
â””â”€â”€ metrics_summary_v2.1.csv

results/
â””â”€â”€ training_history_v2.1_YYYYMMDD_HHMMSS.png
```

### 2. æ¨è«–ãƒ»å¯è¦–åŒ–

```bash
# éç·šå½¢äºˆæ¸¬ã®å¯è¦–åŒ–
python visualize_forecast_v2_1.py
```

å‡ºåŠ›:
```
results/
â””â”€â”€ forecast_comparison_v2.1_YYYYMMDD_HHMMSS.png
```

å¯è¦–åŒ–å†…å®¹:
- éå»90æ—¥ã®å®Ÿç¸¾å€¤ï¼ˆé’ç·šï¼‰
- 3ã¤ã®ãƒ›ãƒ©ã‚¤ã‚ºãƒ³ï¼ˆ30d, 60d, 90dï¼‰ã®éç·šå½¢äºˆæ¸¬ï¼ˆèµ¤/ç·‘ç ´ç·šï¼‰
- ç•°å¸¸ç¢ºç‡ã¨Threshold
- å®Ÿç¸¾ç•°å¸¸æœŸé–“ã®èƒŒæ™¯è‰²

---

## ğŸ“Š Expected Improvements / æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„

### 1. äºˆæ¸¬ç²¾åº¦ã®å‘ä¸Š

| Metric | v2.0 | v2.1 (Expected) | Improvement |
|--------|------|-----------------|-------------|
| **Accuracy** | 91.0-91.2% | 92-93% | +1-2% |
| **F1-Score** | 0.55-0.60 | 0.65-0.70 | +10-15% |
| **ROC-AUC** | 0.85-0.87 | 0.88-0.90 | +2-3% |
| **PR-AUC** | 0.55-0.60 | 0.65-0.70 | +10-15% |

ä¸»ãªè¦å› :
- Focal Lossã«ã‚ˆã‚‹ç•°å¸¸ã‚¯ãƒ©ã‚¹ã®å­¦ç¿’å¼·åŒ–
- çµ±è¨ˆç‰¹å¾´é‡ã®å¤šæ¬¡å…ƒæ´»ç”¨
- LoRA Fine-Tuningã«ã‚ˆã‚‹ãƒ‰ãƒ¡ã‚¤ãƒ³é©å¿œ

### 2. äºˆæ¸¬ã®è§£é‡ˆæ€§å‘ä¸Š

v2.0ï¼ˆç·šå½¢äºˆæ¸¬ï¼‰:
```
äºˆæ¸¬å€¤: ä¸€å®šï¼ˆéå»ã®å¹³å‡çš„ãªå€¤ï¼‰
å•é¡Œç‚¹: ç¾å®Ÿã®ãƒˆãƒ¬ãƒ³ãƒ‰ã¨ä¹–é›¢
```

v2.1ï¼ˆéç·šå½¢äºˆæ¸¬ï¼‰:
```
äºˆæ¸¬å€¤: éå»90æ—¥ã®2æ¬¡ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’å»¶é•·
åˆ©ç‚¹: è¨­å‚™ç®¡ç†è€…ã®ç›´æ„Ÿã«åˆè‡´
```

### 3. èª¤æ¤œçŸ¥ã®å‰Šæ¸›

Focal LossåŠ¹æœ:
- False Positiveå‰Šæ¸›: ç°¡å˜ãªæ­£å¸¸ã‚µãƒ³ãƒ—ãƒ«ã®èª¤åˆ¤å®šã‚’æŠ‘åˆ¶
- False Negativeå‰Šæ¸›: é›£ã—ã„ç•°å¸¸ã‚µãƒ³ãƒ—ãƒ«ã‚’é‡ç‚¹å­¦ç¿’

---

## ğŸ”¬ Technical Details / æŠ€è¡“è©³ç´°

### éç·šå½¢äºˆæ¸¬ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

```python
def generate_nonlinear_forecast(sequence, features, horizon, num_points=30):
    """
    éå»90æ—¥ã‹ã‚‰éç·šå½¢äºˆæ¸¬ã‚’ç”Ÿæˆ
    
    æ‰‹é †:
    1. ç›´è¿‘30æ—¥ã‚’2æ¬¡å¤šé …å¼ã§ãƒ•ã‚£ãƒƒãƒˆ
    2. çµ±è¨ˆç‰¹å¾´é‡ã‹ã‚‰ãƒˆãƒ¬ãƒ³ãƒ‰èª¿æ•´ä¿‚æ•°ã‚’è¨ˆç®—
    3. æ¸›è¡°ä¿‚æ•°ã§éåº¦ãªç™ºæ•£ã‚’æŠ‘åˆ¶
    4. Â±3Ïƒç¯„å›²ã«ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°
    """
    # 1. 2æ¬¡å¤šé …å¼ãƒ•ã‚£ãƒƒãƒˆ
    recent_values = sequence[-30:]
    trend = np.polyfit(range(len(recent_values)), recent_values, 2)
    
    # 2. åŸºæœ¬äºˆæ¸¬
    base_forecast = np.polyval(trend, np.arange(len(recent_values), 
                                                 len(recent_values) + num_points))
    
    # 3. æ¸›è¡°èª¿æ•´
    decay_factor = np.exp(-forecast_x / (horizon * 2))
    adjusted_forecast = (base_forecast - recent_mean) * decay_factor + recent_mean
    
    # 4. ç¯„å›²åˆ¶é™
    adjusted_forecast = np.clip(adjusted_forecast, 
                                mean_val - 3*std_val, 
                                mean_val + 3*std_val)
    
    return adjusted_forecast
```

åˆ©ç‚¹:
- **2æ¬¡å¤šé …å¼**: åŠ é€Ÿåº¦å¤‰åŒ–ã‚’æ‰ãˆã‚‹
- **æ¸›è¡°ä¿‚æ•°**: é•·æœŸäºˆæ¸¬ã®ä¸ç¢ºå®Ÿæ€§ã‚’è€ƒæ…®
- **3Ïƒã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°**: ç‰©ç†çš„ã«å¦¥å½“ãªç¯„å›²ã«åˆ¶é™

### Focal Loss vs Binary Cross Entropy

#### Binary Cross Entropy (v2.0)
```
Loss = -[y*log(p) + (1-y)*log(1-p)]
```

å•é¡Œç‚¹:
- ç°¡å˜ãªã‚µãƒ³ãƒ—ãƒ«ã‚‚é›£ã—ã„ã‚µãƒ³ãƒ—ãƒ«ã‚‚åŒç­‰ã«æ‰±ã†
- ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ã§å¤šæ•°ã‚¯ãƒ©ã‚¹ã«åã‚‹

#### Focal Loss (v2.1)
```
Loss = -alpha * (1-p_t)^gamma * log(p_t)
```

æ”¹å–„ç‚¹:
- $(1-p_t)^3$: é«˜ç¢ºä¿¡åº¦ã‚µãƒ³ãƒ—ãƒ«ã®æå¤±ã‚’å¤§å¹…å‰Šæ¸›
- $\alpha$: å°‘æ•°ã‚¯ãƒ©ã‚¹ã¸ã®ãƒãƒ©ãƒ³ã‚¹èª¿æ•´
- çµæœ: é›£ã—ã„ç•°å¸¸ã‚µãƒ³ãƒ—ãƒ«ã«é›†ä¸­å­¦ç¿’

---

## ğŸ“ˆ Monitoring & Evaluation / ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ãƒ»è©•ä¾¡

### è¨“ç·´ä¸­ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹

```python
# å„ã‚¨ãƒãƒƒã‚¯ã§è¡¨ç¤º
Epoch 1/15 | Train Loss: 0.1234 | Test Loss: 0.1456 | 
            F1: 0.6789 | Acc: 0.9123 | Threshold: 0.456
```

ç›£è¦–ãƒã‚¤ãƒ³ãƒˆ:
- **Train Lossæ¸›å°‘**: ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ä¸­
- **Test Losså®‰å®š**: éå­¦ç¿’ãªã—
- **F1-Scoreå‘ä¸Š**: ç•°å¸¸æ¤œå‡ºæ€§èƒ½æ”¹å–„
- **Thresholdå¤‰åŒ–**: æœ€é©é–¾å€¤ã®æ¢ç´¢

### æœ€çµ‚è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹

```python
# ãƒ¢ãƒ‡ãƒ«ä¿å­˜æ™‚ã«è¡¨ç¤º
  Accuracy: 0.9234
  Precision: 0.7890
  Recall: 0.6543
  F1-Score: 0.7123
  ROC-AUC: 0.8901
  PR-AUC: 0.6789
```

é‡è¦æŒ‡æ¨™:
- **F1-Score**: Precision-Recallã®ãƒãƒ©ãƒ³ã‚¹
- **PR-AUC**: ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã§ã®æ€§èƒ½
- **Recall**: ç•°å¸¸ã®è¦‹é€ƒã—ç‡ï¼ˆè¨­å‚™ç®¡ç†ã§é‡è¦ï¼‰

---

## ğŸ“ Lessons Learned / å­¦ã‚“ã ã“ã¨

### 1. Feature Fusionã®é‡è¦æ€§
- åŸ‹ã‚è¾¼ã¿ã¨çµ±è¨ˆç‰¹å¾´ã®çµ±åˆã§æ€§èƒ½ãŒå¤§å¹…å‘ä¸Š
- ç•°ãªã‚‹æƒ…å ±æºã®ç›¸è£œçš„æ´»ç”¨

### 2. Focal Lossã®åŠ¹æœ
- ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã§é¡•è‘—ãªæ”¹å–„
- gamma=3ãŒæœ€é©ï¼ˆå®Ÿé¨“çµæœï¼‰

### 3. éç·šå½¢äºˆæ¸¬ã®å¿…è¦æ€§
- ç·šå½¢äºˆæ¸¬ã¯ç²¾åº¦ãŒé«˜ãã¦ã‚‚å®Ÿç”¨æ€§ã«æ¬ ã‘ã‚‹
- ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã®æ´»ç”¨ï¼ˆ2æ¬¡ãƒˆãƒ¬ãƒ³ãƒ‰ã€æ¸›è¡°ä¿‚æ•°ï¼‰

### 4. LoRA Fine-Tuningã®åŠ¹ç‡æ€§
- å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°ä¸è¦ï¼ˆ22%ã®ã¿ï¼‰
- è¨“ç·´æ™‚é–“çŸ­ç¸®ã€éå­¦ç¿’æŠ‘åˆ¶

---

## ğŸ”„ Future Work / ä»Šå¾Œã®å±•é–‹

### v2.2ã¸ã®æ”¹å–„æ¡ˆ

1. **Attentionæ©Ÿæ§‹ã®å°å…¥**
   - éå»90æ—¥ã®é‡è¦ãªæ™‚ç‚¹ã‚’è‡ªå‹•é¸æŠ
   - å­£ç¯€æ€§ãƒ»å‘¨æœŸæ€§ã®è€ƒæ…®

2. **Multi-Task Learning**
   - è¤‡æ•°ãƒ›ãƒ©ã‚¤ã‚ºãƒ³ã‚’åŒæ™‚å­¦ç¿’
   - å…±é€šç‰¹å¾´ã®åŠ¹ç‡çš„æŠ½å‡º

3. **Uncertainty Quantification**
   - äºˆæ¸¬ã®ä¿¡é ¼åŒºé–“
   - Monte Carlo Dropout

4. **Online Learning**
   - æ–°ãƒ‡ãƒ¼ã‚¿ã§ã®ç¶™ç¶šå­¦ç¿’
   - Concept Driftã¸ã®å¯¾å¿œ

---

## ğŸ“š References / å‚è€ƒæ–‡çŒ®

1. **Focal Loss for Dense Object Detection** (Lin et al., 2017)
   - https://arxiv.org/abs/1708.02002

2. **LoRA: Low-Rank Adaptation of Large Language Models** (Hu et al., 2021)
   - https://arxiv.org/abs/2106.09685

3. **TinyTimeMixer** (IBM Research)
   - Lightweight time series forecasting

4. **LightGBM: A Highly Efficient Gradient Boosting Decision Tree** (Ke et al., 2017)
   - https://papers.nips.cc/paper/6907-lightgbm

---

## ğŸ“ Changelog / å¤‰æ›´å±¥æ­´

### v2.1 (2026-02-15)
- âœ… Statistical Featureså¤šæ¬¡å…ƒã‚¤ãƒ³ãƒ—ãƒƒãƒˆ
- âœ… TinyTimeMixer LoRA Fine-Tuning
- âœ… Focal Loss (beta=3)å®Ÿè£…
- âœ… éç·šå½¢äºˆæ¸¬ç”Ÿæˆã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
- âœ… æ‹¡å¼µå¯è¦–åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

### v2.0 (2026-02-10)
- TinyTimeMixeråŸ‹ã‚è¾¼ã¿ + LightGBM
- 3ãƒ›ãƒ©ã‚¤ã‚ºãƒ³äºˆæ¸¬ï¼ˆ30d, 60d, 90dï¼‰
- åŸºæœ¬çš„ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°

### v1.1 (2026-02-05)
- 64è¨­å‚™ã§ã®å®Ÿé¨“
- çµ±è¨ˆç‰¹å¾´é‡ã®è¿½åŠ 

### v1.0 (2026-02-01)
- Top 5è¨­å‚™ã§ã®åˆæœŸå®Ÿé¨“
- åŸºæœ¬çš„ãªLSTMãƒ¢ãƒ‡ãƒ«

---

**Author**: HVAC Anomaly Detection Team  
**Last Updated**: 2026-02-15  
**Status**: Ready for Training ğŸš€
