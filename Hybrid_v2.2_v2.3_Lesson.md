# Hybrid Model v2.2 vs v2.2.2 vs v2.3: Feature Fusion Architecture ã®æ¯”è¼ƒ

**ä½œæˆæ—¥**: 2026å¹´2æœˆ15æ—¥  
**æœ€çµ‚æ›´æ–°**: 2026å¹´2æœˆ15æ—¥  
**ãƒ†ãƒ¼ãƒ**: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã¨Fusionæˆ¦ç•¥ã®ä¾¡å€¤æ¤œè¨¼

---

## ğŸ“Œ Executive Summary

v2.2ï¼ˆSimple Concat Fusionï¼‰ã€v2.2.2ï¼ˆCross-Attention Fusionï¼‰ã€v2.3ï¼ˆNo Statistical Featuresï¼‰ã®æ¯”è¼ƒå®Ÿé¨“ã«ã‚ˆã‚Šã€**æ˜ç¤ºçš„ãªçµ±è¨ˆç‰¹å¾´é‡ã®é‡è¦æ€§**ã¨**Simple Fusionæˆ¦ç•¥ã®æœ‰åŠ¹æ€§**ãŒå®Ÿè¨¼ã•ã‚Œã¾ã—ãŸã€‚

**çµè«–**: **v2.2ã‚’Production Modelã¨ã—ã¦ç¢ºå®š**ã€‚Feature Engineering ã¯ä¸å¯æ¬ ã€‚éåº¦ãªè¤‡é›‘æ€§ã¯ä¸è¦ã€‚

---

## ğŸ¯ å®Ÿé¨“ç›®çš„

v2.2ã§ã€Œã‚¤ãƒ³ãƒ—ãƒƒãƒˆãŒé‡ã„ã€ã¨ã„ã†èª²é¡Œèªè­˜ãŒã‚ã‚Šã€Statistical Featuresï¼ˆ28æ¬¡å…ƒï¼‰ã‚’å‰Šé™¤ã—ã¦TinyTimeMixer Embeddingsï¼ˆ64æ¬¡å…ƒï¼‰ã®ã¿ã§å­¦ç¿’ã§ãã‚‹ã‹æ¤œè¨¼ã€‚

**ä»®èª¬**: TinyTimeMixerã®æ™‚ç³»åˆ—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãŒçµ±è¨ˆæƒ…å ±ã‚’å†…åŒ…ã—ã¦ã„ã‚‹ãŸã‚ã€æ˜ç¤ºçš„ãªçµ±è¨ˆç‰¹å¾´é‡ã¯ä¸è¦ã‹ã‚‚ã—ã‚Œãªã„ã€‚

**çµæœ**: **ä»®èª¬ã¯æ£„å´** â†’ çµ±è¨ˆç‰¹å¾´é‡ã¯å¿…é ˆ

---

## ğŸ“Š Performance Comparison

### v2.2: Simple Concat Fusion âœ… PRODUCTION MODEL

| Metric             | 30d    | 60d    | 90d    | **Average**   |
| ------------------ | ------ | ------ | ------ | ------------------- |
| **F1-Score** | 0.2771 | 0.2756 | 0.2840 | **0.2789** âœ… |
| **ROC-AUC**  | 0.7230 | 0.6981 | 0.6958 | **0.7056**    |
| Precision          | 0.2404 | 0.2435 | 0.2634 | 0.2491              |
| Recall             | 0.3257 | 0.3173 | 0.3101 | 0.3177              |
| Accuracy           | 0.8318 | 0.8349 | 0.8486 | 0.8384              |

**Architecture**:

```
TinyTimeMixer (64d) â”€â”€â”
                      â”œâ†’ Simple Concat (92d) â†’ Linear Fusion (128d) â†’ Multi-Task Heads
Statistical (28d) â”€â”€â”€â”€â”˜
```

**Parameters**: 195,204 total, 61,766 trainable (31.64%)  
**Training**: Epoch 25, Best Avg F1: 0.2789

---

### v2.2.2: Cross-Attention Fusion

| Metric             | 30d    | 60d    | 90d    | **Average**   |
| ------------------ | ------ | ------ | ------ | ------------------- |
| **F1-Score** | 0.2660 | 0.2602 | 0.2805 | **0.2689** âš ï¸ |
| **ROC-AUC**  | 0.7077 | 0.6849 | 0.6900 | **0.6942**    |
| Precision          | 0.1985 | 0.2289 | 0.2386 | 0.2220              |
| Recall             | 0.4031 | 0.3014 | 0.3401 | 0.3482              |
| Accuracy           | 0.8006 | 0.8446 | 0.8340 | 0.8264              |

**Architecture**:

```
TinyTimeMixer (64d) â”€â”€â”
                      â”œâ†’ Bidirectional Cross-Attention â†’ Fused (128d) â†’ Multi-Task Heads
Statistical (28d) â”€â”€â”€â”€â”˜
                      
  1. Embeddings attend to Features
  2. Features attend to Embeddings
```

**Parameters**: 218,952 total, 85,514 trainable (39.06%)  
**Training**: Epoch 25, Best Avg F1: 0.2689

---

### v2.3: No Statistical Features (Time-Series Only)

| Metric             | 30d    | 60d    | 90d    | **Average**   |
| ------------------ | ------ | ------ | ------ | ------------------- |
| **F1-Score** | 0.1924 | 0.1995 | 0.2001 | **0.1973** âŒ |
| **ROC-AUC**  | 0.5865 | 0.5961 | 0.5797 | **0.5874**    |
| Precision          | 0.1222 | 0.1221 | 0.1213 | 0.1219              |
| Recall             | 0.4515 | 0.5460 | 0.6214 | 0.5396              |
| Accuracy           | 0.6601 | 0.6027 | 0.5274 | 0.5967              |

**Architecture**:

```
TinyTimeMixer (64d) â†’ Direct Hidden Layer (64d â†’ 128d) â†’ Multi-Task Heads
```

**Parameters**: 191,620 total, 58,182 trainable (30.36%)

---

## ğŸ“‰ Performance Gap Analysis

| Metric               | v2.2 âœ… | v2.2.2  | v2.3    | v2.2.2 vs v2.2 | v2.3 vs v2.2 |
| -------------------- | ------- | ------- | ------- | -------------- | ------------ |
| **Average F1** | **0.2789** | 0.2689  | 0.1973  | **-3.6%** âš ï¸  | **-29.2%** âŒ |
| Average ROC-AUC      | **0.7056** | 0.6942  | 0.5874  | -1.6%          | -16.8%       |
| Average Precision    | **0.2491** | 0.2220  | 0.1219  | -10.9%         | -51.1%       |
| Average Recall       | 0.3177  | **0.3482** | 0.5396  | +9.6%          | +69.9%       |
| Average Accuracy     | **0.8384** | 0.8264  | 0.5967  | -1.4%          | -28.8%       |
| **Parameters**       | 195,204 | 218,952 | 191,620 | **+12.2%**     | -1.8%        |
| **Trainable %**      | 31.64%  | 39.06%  | 30.36%  | +7.4pt         | -1.3pt       |

### ğŸ” Key Observations
#### v2.2.2 vs v2.2ï¼ˆCross-Attentionå®Ÿé¨“ï¼‰

1. **F1-Scoreå¾®æ¸›**: -3.6%ä½ä¸‹ï¼ˆ0.2789 â†’ 0.2689ï¼‰
2. **ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¢—åŠ **: +12.2%ï¼ˆ195,204 â†’ 218,952ï¼‰
3. **è¨“ç·´å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¢—**: 31.64% â†’ 39.06%ï¼ˆ+7.4ptï¼‰
4. **ROC-AUCå¾®æ¸›**: -1.6%ï¼ˆ0.7056 â†’ 0.6942ï¼‰
5. **è¤‡é›‘æ€§ vs æ€§èƒ½**: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¢—ã§ã‚‚æ€§èƒ½å‘ä¸Šã›ãš

#### v2.3 vs v2.2ï¼ˆçµ±è¨ˆç‰¹å¾´é‡å‰Šé™¤å®Ÿé¨“ï¼‰

1. **F1-Scoreå¤§å¹…ä½ä¸‹**: -29.2%ã®æ€§èƒ½åŠ£åŒ–
2. **Precisionå´©å£Š**: åŠæ¸›ï¼ˆ0.2491 â†’ 0.1219ï¼‰ï¼ˆv2.3å®Ÿé¨“ã‹ã‚‰ï¼‰
3. **Recalléå‰°**: +69.9%å¢—åŠ ï¼ˆéæ¤œå‡ºå‚¾å‘ï¼‰
4. **ROC-AUCå¤§å¹…ä½ä¸‹**: 0.7056 â†’ 0.5874ï¼ˆãƒ©ãƒ³ãƒ€ãƒ åˆ†é¡ã«è¿‘ã„ï¼‰
5. **ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å‰Šæ¸›åŠ¹æœã¯å¾®å°**: ã‚ãšã‹-1.8%5874ï¼ˆãƒ©ãƒ³ãƒ€ãƒ åˆ†é¡ã«è¿‘ã„ï¼‰
5. **ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å‰Šæ¸›åŠ¹æœã¯å¾®å°**: ã‚ãšã‹1.8%æ¸›

---

## ğŸ’¡ Critical Lessons

### âœ… Lesson 1: Statistical Features ã¯ä¸å¯æ¬ 

**ç™ºè¦‹**: TinyTimeMixerã®embeddingsã ã‘ã§ã¯ã€çµ±è¨ˆçš„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ååˆ†ã«æ‰ãˆã‚‰ã‚Œãªã„ã€‚

**v2.2ã®Statistical Features (28æ¬¡å…ƒ)**:

```python
# Time-Series Statistics (7)
- values_mean: éå»90æ—¥ã®å¹³å‡
- values_std: æ¨™æº–åå·®
- values_min / max: ç¯„å›²
- values_range: ãƒ¬ãƒ³ã‚¸å¹…
- values_cv: å¤‰å‹•ä¿‚æ•°
- values_trend: ãƒˆãƒ¬ãƒ³ãƒ‰å‚¾å‘

# Recent Behavior (9)
- values_recent_mean: ç›´è¿‘30æ—¥å¹³å‡
- values_recent_std: ç›´è¿‘30æ—¥æ¨™æº–åå·®
- values_spike_count: ã‚¹ãƒ‘ã‚¤ã‚¯å›æ•°
- values_sudden_change: æ€¥å¤‰å›æ•°
- ...

# Seasonal & Autocorrelation (4)
- values_lag1_corr: 1æ—¥ãƒ©ã‚°è‡ªå·±ç›¸é–¢
- values_seasonal_strength: å­£ç¯€æ€§å¼·åº¦
- ...

# Distribution Features (8)
- values_skewnesSimple Fusion > Complex Fusionï¼ˆv2.2.2å®Ÿé¨“ã‹ã‚‰ï¼‰

**ç™ºè¦‹**: Cross-Attentionã«ã‚ˆã‚‹å‹•çš„é‡ã¿ä»˜ã‘ã‚ˆã‚Šã€Simple Concatã®æ–¹ãŒåŠ¹æœçš„ã€‚

**v2.2.2ï¼ˆCross-Attentionï¼‰ã®å•é¡Œç‚¹:**
- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¢—åŠ : +12.2%ï¼ˆ23,748ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¿½åŠ ï¼‰
- F1-Scoreä½ä¸‹: -3.6%ï¼ˆ0.2789 â†’ 0.2689ï¼‰
- è¨“ç·´å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¢—: 39.06%ï¼ˆéå­¦ç¿’ãƒªã‚¹ã‚¯å¢—ï¼‰
- è¤‡é›‘æ€§ã«è¦‹åˆã†æ€§èƒ½å‘ä¸Šãªã—

**ç†ç”±ã®è€ƒå¯Ÿ:**
1. **ç‰¹å¾´é‡ãŒå°‘ãªã„**: 28æ¬¡å…ƒã®çµ±è¨ˆç‰¹å¾´ã«å¯¾ã—ã¦Cross-Attentionã¯éå‰°
2. **æƒ…å ±å¯†åº¦ãŒé«˜ã„**: Simple Concatã§æ—¢ã«ååˆ†ãªæƒ…å ±çµ±åˆ
3. **æ­£å‰‡åŒ–åŠ¹æœã®æ¸›å°‘**: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¢—ã«ã‚ˆã‚Šéå­¦ç¿’å‚¾å‘
4. **è¨“ç·´ãƒ‡ãƒ¼ã‚¿ä¸è¶³**: Cross-Attentionã®æ©æµã‚’å¾—ã‚‹ã«ã¯ã‚ˆã‚Šå¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦

**æ•™è¨“:**
```
Architectural Complexity â‰  Better Performance

Simple Concat Fusion (v2.2):
  - Efficient: 195,204 params
  - Effective: F1=0.2789
  - Stable: 31.64% trainable
4
Cross-Attention Fusion (v2.2.2):
  - Complex: 218,952 params (+12%)
  - Less Effective: F1=0.2689 (-4%)
  - Overfitting Risk: 39.06% trainable
```

**çµè«–**: 28æ¬¡å…ƒã®çµ±è¨ˆç‰¹å¾´é‡ã«å¯¾ã—ã¦ã¯ã€Simple ConcatãŒæœ€é©ã€‚Cross-Attentionã¯ç‰¹å¾´é‡ãŒå¤šã„ï¼ˆ100+æ¬¡å…ƒï¼‰å ´åˆã«æœ‰åŠ¹ã€‚

---

### âœ… Lesson 3: s: æ­ªåº¦
- values_kurtosis: å°–åº¦
- values_entropy: ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼
- ...
```

ã“ã‚Œã‚‰ã®**æ˜ç¤ºçš„ãªçµ±è¨ˆé‡5*ãŒã€ç•°å¸¸æ¤œçŸ¥ã®åˆ¤æ–­ã«é‡è¦ãªå½¹å‰²ã‚’æœãŸã—ã¦ã„ã‚‹ã€‚

---

### âœ… Lesson 2: Precision vs Recall ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•

**v2.3ã®å•é¡Œç‚¹**: RecallãŒé«˜ã„ï¼ˆ0.54ï¼‰ãŒã€PrecisionãŒä½ã„ï¼ˆ0.12ï¼‰

- **æ„å‘³**: ç•°å¸¸ã‚’éå‰°ã«æ¤œå‡ºï¼ˆå½é™½æ€§ãŒå¤šã„ï¼‰
- **åŸå› **: çµ±è¨ˆç‰¹å¾´é‡ãŒãªã„ãŸã‚ã€æ­£å¸¸ç¯„å›²å†…ã®å¤‰å‹•ã¨ç•°å¸¸ã‚’åŒºåˆ¥ã§ããªã„

**v2.2ã®å¼·ã¿**: Precision 0.25ã€Recall 0.32 ã®ãƒãƒ©ãƒ³ã‚¹

- Mean/Stdãªã©ã®çµ±è¨ˆé‡ã§ã€æ­£å¸¸ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ç¢ºç«‹
- çœŸã®ç•°å¸¸ã®ã¿ã‚’æ¤œå‡º

---

### âœ… Lesson 3: Feature Engineering > Model Complexity

**åˆ¤æ˜ã—ãŸäº‹å®Ÿ**:

- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å‰Šæ¸›: ã‚ãšã‹1.8%ï¼ˆ3,584ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
- æ€§èƒ½ä½ä¸‹: 29.2%ï¼ˆF1-Scoreï¼‰

**çµè«–**:

```
å°‘æ•°ã®è‰¯è³ªãªç‰¹å¾´é‡ >> è¤‡é›‘ãªãƒ¢ãƒ‡ãƒ«æ§‹é€ 
```

Feature Engineeringï¼ˆç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼‰ã¸ã®æŠ•è³‡ã¯ã€ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆã®æœ€é©åŒ–ã‚ˆã‚Šã‚‚**é«˜ROI**ã€‚

---

### âœ… Lesson 4: "é‡ã„"ã¯å¿…ãšã—ã‚‚æ‚ªã§ã¯ãªã„

**v2.2ã¸ã®åçœ**:

- ã€Œ92æ¬¡å…ƒã¯é‡ã„ã€ã¨ã„ã†ä¸»è¦³çš„åˆ¤æ–­
- å®Ÿéš›ã«ã¯å¿…è¦ãªæƒ…å ±å¯†åº¦ã ã£ãŸ

**æ•™è¨“**:
2.2 å¤±æ•—è¦å› ï¼ˆCross-Attentionï¼‰

1. **éå‰°ãªè¤‡é›‘æ€§**
   - 28æ¬¡å…ƒã®ç‰¹å¾´é‡ã«å¯¾ã—ã¦Cross-Attentionã¯éå‰°è¨­è¨ˆ
   - Multi-head Attentionï¼ˆ4 headsï¼‰Ã— 2æ–¹å‘ = éåº¦ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–

2. **ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŠ¹ç‡ã®æ‚ªåŒ–**
   - +23,748ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆ+12.2%ï¼‰ã§-3.6% F1ä½ä¸‹
   - ROIï¼ˆæŠ•è³‡å¯¾åŠ¹æœï¼‰ãŒè² 

3. **è¨“ç·´å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å¢—åŠ **
   - 31.64% â†’ 39.06%ï¼ˆ+7.4ptï¼‰
   - éå­¦ç¿’ãƒªã‚¹ã‚¯å¢—å¤§ã€æ±åŒ–æ€§èƒ½ä½ä¸‹

4. **ç‰¹å¾´é‡è¦æ¨¡ã¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ãƒŸã‚¹ãƒãƒƒãƒ**
   - Cross-Attentionã¯100+æ¬¡å…ƒã®é«˜æ¬¡å…ƒç‰¹å¾´ã«æœ‰åŠ¹
   - 28æ¬¡å…ƒã§ã¯æƒ…å ±å¯†åº¦ãŒé«˜ã™ãã¦åŠ¹æœè–„

---
 âœ… PRODUCTION MODEL

- **Device**: NVIDIA RTX 4060 Ti (16GB)
- **Training Time**: ~25 epochså®Œäº†
- **Convergence**: Epoch 25ã§Best (Avg F1: 0.2789)
- **Memory**: GPUååˆ†ã«ä½™è£•ã‚ã‚Š
- **Parameters**: 195,204 (æœ€é©ãªãƒãƒ©ãƒ³ã‚¹)

### v2.2.2

- **Device**: NVIDIA RTX 4060 Ti (16GB)
- **Training Time**: ~25 epochså®Œäº†
- **Convergence**: Epoch 25ã§Best (Avg F1: 0.2689)
- **Memory**: GPUååˆ†ã«ä½™è£•ã‚ã‚Š
- **Parameters**: 218,952 (+12.2% vs v2.2)
- **é€Ÿåº¦**: v2.2ã¨ã»ã¼åŒç­‰ï¼ˆCross-Attentionã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰å°ï¼‰

### v2.3

- **Device**: NVIDIA RTX 4060 Ti (16GB)
- **Training Time**: ~25 epochså®Œäº†
- **Convergence**: Epoch 24ã§Best (Avg F1: 0.1973)
- **Memory**: GPUååˆ†ã«ä½™è£•ã‚ã‚Š
- **Parameters**: 191,620 (-1.8% vs v2.2)
- **é€Ÿåº¦æ”¹å–„**: ç‰¹ã«é¡•è‘—ãªæ”¹å–„ãªã—ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ãŒãƒœãƒˆãƒ«ãƒãƒƒã‚¯ï¼‰

**çµè«–**: 
- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¢—åŠ ï¼ˆv2.2.2ï¼‰ã‚‚å‰Šæ¸›ï¼ˆv2.3ï¼‰ã‚‚æ€§èƒ½å‘ä¸Šã«ã¯å¯„ä¸ã›ãš
- v2.2ã®195,204ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒæœ€é©ãªã‚¹ã‚¤ãƒ¼ãƒˆã‚¹ãƒãƒƒãƒˆ
- Simple architectureãŒå®‰å®šæ€§ã¨æ€§èƒ½ã‚’ä¸¡ç«‹r 64d)
   +
   Statistical Summary (Engineered 28d)
   â†“
   Complementary Information Fusion
   ```
2. **Multi-Task Learning**

   - 30d, 60d, 90d ã®3ãƒ›ãƒ©ã‚¤ã‚ºãƒ³ã‚’åŒæ™‚å­¦ç¿’
   - Shared representation learning ã§æ±åŒ–æ€§èƒ½å‘ä¸Š
3. **Focal Loss**

   - Î³=3.0 ã§ hard examples ã«é›†ä¸­
   - Class imbalanceï¼ˆç•°å¸¸ 9%ï¼‰ã¸ã®å¯¾å‡¦
4. **Temporal Attention**

   - 4-head attention ã§ãƒ‘ã‚¿ãƒ¼ãƒ³å¼·èª¿
   - Interpretabilityç¢ºä¿

---

### v2.3 å¤±æ•—è¦å› 

1. **æƒ…å ±ä¸è¶³**

   - TinyTimeMixerã¯æ™‚ç³»åˆ—ã®**å½¢çŠ¶**ã‚’æ‰ãˆã‚‹
   - ã—ã‹ã—**çµ±è¨ˆçš„ç‰¹æ€§**ï¼ˆå¹³å‡ãƒ¬ãƒ™ãƒ«ã€å¤‰å‹•å¹…ï¼‰ã¯å¼±ã„
2. **éæ¤œå‡ºå‚¾å‘**

   - æ­£å¸¸ç¯„å›²ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãŒãªã„
   - å¤‰å‹•ãŒã‚ã‚Œã°å…¨ã¦ç•°å¸¸ã¨åˆ¤æ–­
3. **ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã®æ¬ å¦‚**

   - HVACæ©Ÿå™¨ã®ç•°å¸¸åˆ¤å®šã«ã¯çµ±è¨ˆçš„é–¾å€¤ãŒé‡è¦
   - "å¹³å‡ã‹ã‚‰ä½•Ïƒé›¢ã‚Œã¦ã„ã‚‹ã‹"ãªã©ã®æƒ…å ±ãŒå¿…é ˆ

---
~~Option 3: Attention-based Feature Fusion~~ âŒ åŠ¹æœãªã—

- ~~ç¾çŠ¶: å˜ç´”concat~~
- ~~æ”¹å–„: Cross-attention ã§å‹•çš„ã«é‡ã¿ä»˜ã‘~~
- **å®Ÿé¨“çµæœï¼ˆv2.2.2ï¼‰**: F1-Score -3.6%ä½ä¸‹ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿+12%å¢—åŠ 
- **çµè«–**: 28æ¬¡å…ƒã®ç‰¹å¾´é‡ã«ã¯Simple Concat FusionãŒæœ€é©
- **Cross-AttentionãŒæœ‰åŠ¹ãªã‚±ãƒ¼ã‚¹**: 100+æ¬¡å…ƒã®é«˜æ¬¡å…ƒç‰¹å¾´é‡*Convergence**: Epoch 25ã§Best (Avg F1: 0.2789)
- **Memory**: GPUååˆ†ã«ä½™è£•ã‚ã‚Š

### v2.3

- **Device**: NVIDIA RTX 4060 Ti (16GB)
- **Training Time**: ~25 epochså®Œäº†
- **Convergence**: Epoch 24ã§Best (Avg F1: 0.1973)
- **é€Ÿåº¦æ”¹å–„**: ç‰¹ã«é¡•è‘—ãªæ”¹å–„ãªã—ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ãŒãƒœãƒˆãƒ«ãƒãƒƒã‚¯ï¼‰

**çµè«–**: ç‰¹å¾´é‡å‰Šæ¸›ã«ã‚ˆã‚‹é€Ÿåº¦å‘ä¸Šã¯é™å®šçš„ã€‚æ€§èƒ½çŠ ç‰²ã«è¦‹åˆã‚ãªã„ã€‚

---

## ğŸ“ Broader Implications

### 1. Time-Series Anomaly Detection ã«ãŠã‘ã‚‹ç‰¹å¾´è¨­è¨ˆ

**åŸå‰‡**:

```
Raw Time-Series Embeddings (å½¢çŠ¶æƒ…å ±)
+
Statistical Features (çµ±è¨ˆæƒ…å ±)
= Robust Anomaly Detection
```

### 2. Transfer Learning ã®é™ç•Œ

- äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ï¼ˆTinyTimeMixerï¼‰ã¯æ±ç”¨çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’
- ã—ã‹ã—ãƒ‰ãƒ¡ã‚¤ãƒ³å›ºæœ‰ã®çµ±è¨ˆçš„ç•°å¸¸ã¯æ‰ãˆã‚‰ã‚Œãªã„
- **Domain Adaptation ãŒå¿…è¦**

### 3. Explainability

v2.2ã®åˆ©ç‚¹:

- Statistical features ã¯è§£é‡ˆå¯èƒ½
- ã€Œã“ã®æœŸé–“ã¯å¹³å‡ãŒé«˜ãã€å¤‰å‹•ãŒå¤§ãã„ãŸã‚ç•°å¸¸ã€ã¨èª¬æ˜ã§ãã‚‹

v2.3ã®å•é¡Œ:

- Embeddingç©ºé–“ã®ã¿ â†’ ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹
- äºˆæ¸¬æ ¹æ‹ ã®èª¬æ˜ãŒå›°é›£

---

## ğŸ”® Future Directions

### æ¨å¥¨æˆ¦ç•¥: v2.2 ã‚’ãƒ™ãƒ¼ã‚¹ã«æ”¹å–„

#### Option 1: Feature Selectionï¼ˆç‰¹å¾´é¸æŠï¼‰
 âœ… PRODUCTION: `models/hybrid_model_v2.2/pytorch_model_multitask.pt`
- **v2.2.2 Model** (Experimental): `models/hybrid_model_v2.2.2/pytorch_model_multitask.pt`
- **v2.3 Model** (Experimental): `models/hybrid_model_v2.3/pytorch_model_multitask.pt`
- **Training History**:
  - `results/training_history_v2.2.json` âœ…
  - `results/training_history_v2.2.2.json`
  - `results/training_history_v2.3.json`

### Code

- **v2.2 Training** âœ…: [train_hybrid_model_v2_2.py](train_hybrid_model_v2_2.py)
- **v2.2.2 Training**: [train_hybrid_model_v2_2_2.py](train_hybrid_model_v2_2_2.py)
- **v2.3 Training**: [train_hybrid_model_v2_3.py](train_hybrid_model_v2_3.py)
- **v2.2 Visualization** âœ…-based Feature Fusion

- ç¾çŠ¶: å˜ç´”concat
- æ”¹å–„: Cross-attention ã§å‹•çš„ã«é‡ã¿ä»˜ã‘

```python
fused = CrossAttention(embeddings, statistical_features)
```

#### Option 4: Hierarchical Multi-Task

- Current: Flat multi-task (30d, 60d, 90d)
- Enhanced: Hierarchical (30d â†’ 60d â†’ 90d)
- Long-termäºˆæ¸¬ãŒShort-termäºˆæ¸¬ã‚’æ¡ä»¶ä»˜ã‘

---

## ğŸ“ Action Items

### âœ… Immediate (å®Œäº†)

1. ~~v2.2ãƒ¢ãƒ‡ãƒ«ã‚’production candidateã¨ã—ã¦ä¿å­˜~~
2. ~~v2.3å®Ÿé¨“çµæœã‚’ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåŒ–~~
3. ~~Lessonãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ~~

### ğŸ”„ Next Steps

1. **v2.2 Feature Importance Analysis**

   - SHAP valuesè¨ˆç®—
   - 28ç‰¹å¾´é‡ã®è²¢çŒ®åº¦å¯è¦–åŒ–
2. **v2.2 Visualization Enhancement**

   - Attention weights + Feature importance ã®çµ±åˆå¯è¦–åŒ–
   - ã‚µãƒ³ãƒ—ãƒ«ã”ã¨ã®äºˆæ¸¬æ ¹æ‹ èª¬æ˜
3. **v2.4 Design**

   - Feature selectionå®Ÿè£…
   - é‡è¦åº¦ä¸Šä½15-20ç‰¹å¾´ã®ã¿ä½¿ç”¨
### Core Findings

1. âœ… **Statistical Features (28d) are essential** - 29.2% F1-Score improvement (v2.3å®Ÿé¨“)
2. âœ… **Simple Fusion > Complex Fusion** - Concat outperforms Cross-Attention for 28d features (v2.2.2å®Ÿé¨“)
3. âœ… **Feature Engineering > Model Complexity** - Small features â†’ Large impact
4. âœ… **TinyTimeMixer captures shape, not statistics** - Complementary information needed
5. âœ… **v2.2 is production-ready** - Best balance of performance and interpretability

### Architecture Lessons

6. âš ï¸ **Cross-Attention overhead** - +12% params, -4% performance (v2.2.2)
7. âš ï¸ **Feature dimensionality matters** - Cross-Attention effective for 100+ dims, overkill for 28d
8. âœ… **Simplicity wins** - v2.2's Simple Concat performs best with fewest params
9. âŒ **v2.3 experiment valuable** - Proved the necessity of explicit features
10. âŒ **v2.2.2 experiment valuable** - Proved Simple Fusion superiority

### Production Recommendation

**CONFIRMED: v2.2 as Production Model** âœ…

| Criterion | v2.2 Score |
|-----------|------------|
| Performance | **0.2789 F1** (Best) |
| Parameters | **195,204** (Optimal) |
| Trainable % | **31.64%** (Balanced) |
| Interpretability | **High** (Simple architecture) |
| Stability | **Excellent** (Proven) |
| Deployment Ready | **Yes** |

---

**Conclusion**:

> "The best model is not the most complex, nor the simplest, but the one that captures the right information with the right architecture."

**v2.2ã®æˆåŠŸè¦å› :**
- âœ… Statistical Features (28d) ã«ã‚ˆã‚‹æ˜ç¤ºçš„ãªãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜çµ±åˆ
- âœ… Simple Concat Fusion ã«ã‚ˆã‚‹åŠ¹ç‡çš„ãªç‰¹å¾´çµåˆ
- âœ… æœ€é©ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ï¼ˆ195,204ï¼‰ã¨è¨“ç·´å¯èƒ½æ¯”ç‡ï¼ˆ31.64%ï¼‰
- âœ… Multi-Task Learning ã«ã‚ˆã‚‹å…±é€šè¡¨ç¾å­¦ç¿’
- âœ… Temporal Attention ã«ã‚ˆã‚‹æ™‚ç³»åˆ—ãƒ‘ã‚¿ãƒ¼ãƒ³å¼·èª¿

**v2.2.2ã¨v2.3ã®æ•™è¨“:**
- âŒ Cross-Attentionã¯28æ¬¡å…ƒã«ã¯éå‰°ï¼ˆv2.2.2ï¼‰
- âŒ çµ±è¨ˆç‰¹å¾´ã®å‰Šé™¤ã¯è‡´å‘½çš„ï¼ˆv2.3: -29.2% F1ï¼‰
- âœ… ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯å•é¡Œè¦æ¨¡ã«åˆã‚ã›ã¦è¨­è¨ˆã™ã¹ã
- âœ… ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ï¼ˆçµ±è¨ˆç‰¹å¾´ï¼‰ã¯ä¸å¯æ¬ 

---

**Document Version**: 2.0  
**Last Updated**: 2026-02-15 (v2.2.2å®Ÿé¨“è¿½åŠ )  
**Status**: âœ… Production Model Confirmed (v2.2)  
**Decision**: **v2.2ã‚’Production Modelã¨ã—ã¦ç¢ºå®š**
- **v2.2 Model**: `models/hybrid_model_v2.2/pytorch_model_multitask.pt`
- **v2.3 Model**: `models/hybrid_model_v2.3/pytorch_model_multitask.pt`
- **Training History**:
  - `results/training_history_v2.2.json`
  - `results/training_history_v2.3.json`

### Code

- **v2.2 Training**: [train_hybrid_model_v2_2.py](train_hybrid_model_v2_2.py)
- **v2.3 Training**: [train_hybrid_model_v2_3.py](train_hybrid_model_v2_3.py)
- **v2.2 Visualization**: [visualize_forecast_v2_2.py](visualize_forecast_v2_2.py)
- **v2.3 Visualization**: [visualize_forecast_v2_3.py](visualize_forecast_v2_3.py)

---

## ğŸ¯ Key Takeaways

1. âœ… **Statistical Features (28d) are essential** - 29.2% F1-Score improvement
2. âœ… **Feature Engineering > Model Complexity** - Small features â†’ Large impact
3. âœ… **TinyTimeMixer captures shape, not statistics** - Complementary information needed
4. âœ… **v2.2 is production-ready** - Best balance of performance and interpretability
5. âŒ **v2.3 experiment valuable** - Proved the necessity of explicit features

---

**Conclusion**:

> "The best model is not the simplest, but the one that captures the right information."

v2.2 ã®92æ¬¡å…ƒå…¥åŠ›ã¯ã€æœ€é©ãªæƒ…å ±å¯†åº¦ã‚’æŒã¤ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã ã£ãŸã€‚

---

**Document Version**: 1.0
**Last Updated**: 2026-02-15
**Status**: âœ… Validated & Production-Ready (v2.2)
