"""
Feature Engineering for Pump Range Deviation Forecast
ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°

ç¾åœ¨ã®ç”Ÿã®æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã«åŠ ãˆã¦ã€çµ±è¨ˆçš„ç‰¹å¾´é‡ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§
ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ç²¾åº¦ï¼ˆç‰¹ã«Precisionï¼‰ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚

è¿½åŠ ã™ã‚‹ç‰¹å¾´é‡ï¼š
1. çµ±è¨ˆçš„ç‰¹å¾´é‡ï¼ˆå¹³å‡ã€æ¨™æº–åå·®ã€æ­ªåº¦ã€å°–åº¦ãªã©ï¼‰
2. ãƒˆãƒ¬ãƒ³ãƒ‰ç‰¹å¾´é‡ï¼ˆç·šå½¢å›å¸°ã®å‚¾ãã€å¤‰åŒ–ç‡ãªã©ï¼‰
3. ãƒ¬ãƒ³ã‚¸é–¢é€£ç‰¹å¾´é‡ï¼ˆä¸Šé™/ä¸‹é™ã¾ã§ã®è·é›¢ã€é€¸è„±å›æ•°ãªã©ï¼‰
4. å¤‰å‹•æ€§ç‰¹å¾´é‡ï¼ˆãƒ­ãƒ¼ãƒªãƒ³ã‚°çµ±è¨ˆé‡ãªã©ï¼‰
"""

import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, List
from scipy import stats
from sklearn.linear_model import LinearRegression
import warnings
warnings.filterwarnings('ignore')

from config import (
    PROCESSED_DATA_DIR,
    LOOKBACK_DAYS
)


class FeatureEngineer:
    """ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.feature_names = []
    
    def extract_statistical_features(self, sequence: np.ndarray) -> Dict[str, float]:
        """
        çµ±è¨ˆçš„ç‰¹å¾´é‡ã®æŠ½å‡ºï¼ˆNaN/Infå®‰å…¨ç‰ˆï¼‰
        
        Args:
            sequence: æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ [seq_len]
            
        Returns:
            ç‰¹å¾´é‡ã®è¾æ›¸
        """
        features = {}
        
        # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªãƒ¼ãƒ³
        sequence = np.nan_to_num(sequence, nan=0.0, posinf=0.0, neginf=0.0)
        
        # åŸºæœ¬çµ±è¨ˆé‡
        features['mean'] = float(np.mean(sequence))
        features['std'] = float(np.std(sequence))
        features['min'] = float(np.min(sequence))
        features['max'] = float(np.max(sequence))
        features['median'] = float(np.median(sequence))
        features['range'] = features['max'] - features['min']
        
        # å››åˆ†ä½æ•°
        features['q25'] = float(np.percentile(sequence, 25))
        features['q75'] = float(np.percentile(sequence, 75))
        features['iqr'] = features['q75'] - features['q25']
        
        # æ­ªåº¦ãƒ»å°–åº¦ï¼ˆNaNå¯¾ç­–ï¼‰
        if len(sequence) > 3:
            try:
                skew_val = stats.skew(sequence)
                kurt_val = stats.kurtosis(sequence)
                features['skewness'] = float(skew_val) if np.isfinite(skew_val) else 0.0
                features['kurtosis'] = float(kurt_val) if np.isfinite(kurt_val) else 0.0
            except:
                features['skewness'] = 0.0
                features['kurtosis'] = 0.0
        else:
            features['skewness'] = 0.0
            features['kurtosis'] = 0.0
        
        # å¤‰å‹•ä¿‚æ•°ï¼ˆå®‰å…¨ãªé™¤ç®—ï¼‰
        mean_abs = abs(features['mean'])
        if mean_abs > 1e-10:  # ã‚ˆã‚Šå®‰å…¨ãªé–¾å€¤
            cv_val = features['std'] / mean_abs
            features['cv'] = float(cv_val) if np.isfinite(cv_val) else 0.0
        else:
            features['cv'] = 0.0
        
        return features
    
    def extract_trend_features(self, sequence: np.ndarray) -> Dict[str, float]:
        """
        ãƒˆãƒ¬ãƒ³ãƒ‰ç‰¹å¾´é‡ã®æŠ½å‡ºï¼ˆNaN/Infå®‰å…¨ç‰ˆï¼‰
        
        Args:
            sequence: æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ [seq_len]
            
        Returns:
            ç‰¹å¾´é‡ã®è¾æ›¸
        """
        features = {}
        
        # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªãƒ¼ãƒ³
        sequence = np.nan_to_num(sequence, nan=0.0, posinf=0.0, neginf=0.0)
        
        # ç·šå½¢å›å¸°ã«ã‚ˆã‚‹å‚¾ã
        X = np.arange(len(sequence)).reshape(-1, 1)
        y = sequence.reshape(-1, 1)
        
        try:
            model = LinearRegression()
            model.fit(X, y)
            slope = float(model.coef_[0][0])
            intercept = float(model.intercept_[0])
            features['trend_slope'] = slope if np.isfinite(slope) else 0.0
            features['trend_intercept'] = intercept if np.isfinite(intercept) else float(sequence[0])
        except:
            features['trend_slope'] = 0.0
            features['trend_intercept'] = float(sequence[0])
        
        # æœ€è¿‘ã®æœŸé–“ vs éå»ã®æœŸé–“ï¼ˆå®‰å…¨ãªé™¤ç®—ï¼‰
        if len(sequence) >= 60:
            recent_mean = float(np.mean(sequence[-30:]))  # æœ€è¿‘30æ—¥
            past_mean = float(np.mean(sequence[-60:-30]))  # éå»30æ—¥
            
            if abs(past_mean) > 1e-10:
                ratio = recent_mean / past_mean
                features['recent_vs_past_ratio'] = float(ratio) if np.isfinite(ratio) else 1.0
                features['recent_vs_past_diff'] = float(recent_mean - past_mean)
            else:
                features['recent_vs_past_ratio'] = 1.0
                features['recent_vs_past_diff'] = 0.0
        else:
            features['recent_vs_past_ratio'] = 1.0
            features['recent_vs_past_diff'] = 0.0
        
        # æœ€çµ‚å€¤ã®å¤‰åŒ–ç‡
        if len(sequence) >= 10:
            recent_slope = float((sequence[-1] - sequence[-10]) / 10)
            features['recent_change_rate'] = recent_slope if np.isfinite(recent_slope) else 0.0
        else:
            features['recent_change_rate'] = 0.0
        
        return features
    
    def extract_range_features(
        self, 
        sequence: np.ndarray,
        upper_limit: float,
        lower_limit: float
    ) -> Dict[str, float]:
        """
        ãƒ¬ãƒ³ã‚¸é–¢é€£ç‰¹å¾´é‡ã®æŠ½å‡ºï¼ˆNaN/Infå®‰å…¨ç‰ˆï¼‰
        
        Args:
            sequence: æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ [seq_len]
            upper_limit: ä¸Šé™å€¤
            lower_limit: ä¸‹é™å€¤
            
        Returns:
            ç‰¹å¾´é‡ã®è¾æ›¸
        """
        features = {}
        
        # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªãƒ¼ãƒ³
        sequence = np.nan_to_num(sequence, nan=0.0, posinf=0.0, neginf=0.0)
        
        # ä¸Šé™/ä¸‹é™ã¾ã§ã®è·é›¢
        distance_to_upper = upper_limit - sequence
        distance_to_lower = sequence - lower_limit
        
        features['mean_distance_to_upper'] = float(np.mean(distance_to_upper))
        features['mean_distance_to_lower'] = float(np.mean(distance_to_lower))
        features['min_distance_to_upper'] = float(np.min(distance_to_upper))
        features['min_distance_to_lower'] = float(np.min(distance_to_lower))
        
        # ãƒ¬ãƒ³ã‚¸ä¸­å¿ƒã‹ã‚‰ã®è·é›¢
        range_center = (upper_limit + lower_limit) / 2
        range_width = upper_limit - lower_limit
        
        features['mean_distance_to_center'] = float(np.mean(np.abs(sequence - range_center)))
        
        if range_width > 1e-10:  # å®‰å…¨ãªé–¾å€¤
            rel_pos = np.mean((sequence - lower_limit) / range_width)
            features['relative_position'] = float(rel_pos) if np.isfinite(rel_pos) else 0.5
        else:
            features['relative_position'] = 0.5
        
        # ãƒ¬ãƒ³ã‚¸å†…æ»åœ¨ç‡
        in_range = (sequence >= lower_limit) & (sequence <= upper_limit)
        features['in_range_ratio'] = np.mean(in_range)
        
        # ãƒ¬ãƒ³ã‚¸é€¸è„±å›æ•°
        features['out_of_range_count'] = np.sum(~in_range)
        
        # é€£ç¶šã—ã¦ãƒ¬ãƒ³ã‚¸å†…ã«ã„ã‚‹æœ€å¤§æ—¥æ•°
        consecutive_in_range = []
        current_streak = 0
        for val in in_range:
            if val:
                current_streak += 1
            else:
                if current_streak > 0:
                    consecutive_in_range.append(current_streak)
                current_streak = 0
        if current_streak > 0:
            consecutive_in_range.append(current_streak)
        
        features['max_consecutive_in_range'] = max(consecutive_in_range) if consecutive_in_range else 0
        
        # ä¸Šé™/ä¸‹é™è¶…éã®å‰²åˆ
        features['above_upper_ratio'] = np.mean(sequence > upper_limit)
        features['below_lower_ratio'] = np.mean(sequence < lower_limit)
        
        return features
    
    def extract_volatility_features(self, sequence: np.ndarray) -> Dict[str, float]:
        """
        å¤‰å‹•æ€§ç‰¹å¾´é‡ã®æŠ½å‡ºï¼ˆNaN/Infå®‰å…¨ç‰ˆï¼‰
        
        Args:
            sequence: æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ [seq_len]
            
        Returns:
            ç‰¹å¾´é‡ã®è¾æ›¸
        """
        features = {}
        
        # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªãƒ¼ãƒ³
        sequence = np.nan_to_num(sequence, nan=0.0, posinf=0.0, neginf=0.0)
        
        # å·®åˆ†ç³»åˆ—
        diff = np.diff(sequence)
        diff = np.nan_to_num(diff, nan=0.0, posinf=0.0, neginf=0.0)
        
        features['diff_mean'] = float(np.mean(diff))
        features['diff_std'] = float(np.std(diff))
        features['diff_abs_mean'] = float(np.mean(np.abs(diff)))
        
        # ãƒ­ãƒ¼ãƒªãƒ³ã‚°çµ±è¨ˆé‡ï¼ˆ7æ—¥ã€14æ—¥ã€30æ—¥ï¼‰
        for window in [7, 14, 30]:
            if len(sequence) >= window:
                rolling_std = []
                for i in range(len(sequence) - window + 1):
                    window_std = float(np.std(sequence[i:i+window]))
                    if np.isfinite(window_std):
                        rolling_std.append(window_std)
                
                if len(rolling_std) > 0:
                    features[f'rolling_std_{window}d_mean'] = float(np.mean(rolling_std))
                    features[f'rolling_std_{window}d_max'] = float(np.max(rolling_std))
                else:
                    features[f'rolling_std_{window}d_mean'] = 0.0
                    features[f'rolling_std_{window}d_max'] = 0.0
            else:
                features[f'rolling_std_{window}d_mean'] = 0.0
                features[f'rolling_std_{window}d_max'] = 0.0
        
        # æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ï¼ˆãƒ”ãƒ¼ã‚¯ã‹ã‚‰ã®æœ€å¤§ä¸‹è½ï¼‰
        cummax = np.maximum.accumulate(sequence)
        drawdown = cummax - sequence
        drawdown = np.nan_to_num(drawdown, nan=0.0, posinf=0.0, neginf=0.0)
        features['max_drawdown'] = float(np.max(drawdown))
        features['mean_drawdown'] = float(np.mean(drawdown))
        
        return features
    
    def extract_all_features(
        self,
        sequence: np.ndarray,
        upper_limit: float = None,
        lower_limit: float = None
    ) -> Dict[str, float]:
        """
        å…¨ç‰¹å¾´é‡ã®æŠ½å‡º
        
        Args:
            sequence: æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ [seq_len]
            upper_limit: ä¸Šé™å€¤ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            lower_limit: ä¸‹é™å€¤ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            
        Returns:
            å…¨ç‰¹å¾´é‡ã®è¾æ›¸
        """
        all_features = {}
        
        # å…¥åŠ›ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ï¼ˆæœ€åˆã«å®Ÿè¡Œï¼‰
        sequence = np.nan_to_num(sequence, nan=0.0, posinf=0.0, neginf=0.0)
        
        # å„ç¨®ç‰¹å¾´é‡ã‚’æŠ½å‡º
        all_features.update(self.extract_statistical_features(sequence))
        all_features.update(self.extract_trend_features(sequence))
        
        # ãƒ¬ãƒ³ã‚¸é–¢é€£ç‰¹å¾´é‡ï¼ˆãƒ¬ãƒ³ã‚¸æƒ…å ±ãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰
        if upper_limit is not None and lower_limit is not None:
            all_features.update(self.extract_range_features(sequence, upper_limit, lower_limit))
        
        all_features.update(self.extract_volatility_features(sequence))
        
        # æœ€çµ‚çš„ãªNaN/Infãƒã‚§ãƒƒã‚¯ï¼ˆå…¨ç‰¹å¾´é‡ã«å¯¾ã—ã¦ï¼‰
        for key, value in all_features.items():
            if not np.isfinite(value):
                all_features[key] = 0.0  # NaN/Infã¯0.0ã«ç½®æ›
        
        return all_features
    
    def enrich_training_samples(self, input_path: str = None, output_path: str = None):
        """
        è¨“ç·´ã‚µãƒ³ãƒ—ãƒ«ã«ç‰¹å¾´é‡ã‚’è¿½åŠ 
        
        Args:
            input_path: å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        if input_path is None:
            input_path = PROCESSED_DATA_DIR / "training_samples.csv"
        else:
            input_path = Path(input_path)
        
        if output_path is None:
            output_path = PROCESSED_DATA_DIR / "training_samples_enriched.csv"
        else:
            output_path = Path(output_path)
        
        print("="*70)
        print("ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°")
        print("="*70)
        
        print(f"\nğŸ“‚ Loading data from: {input_path}")
        df = pd.read_csv(input_path)
        print(f"âœ“ Loaded {len(df):,} samples")
        
        print("\nğŸ”§ Extracting features...")
        
        enriched_features = []
        
        for idx, row in df.iterrows():
            # ç³»åˆ—ãƒ‡ãƒ¼ã‚¿å–å¾—
            if isinstance(row['values_sequence'], str):
                import ast
                values = ast.literal_eval(row['values_sequence'])
            else:
                values = row['values_sequence']
            
            sequence = np.array(values, dtype=np.float32)
            
            # ãƒ¬ãƒ³ã‚¸æƒ…å ±ã®å–å¾—ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿ï¼‰
            upper_limit = row.get('upper_limit', None)
            lower_limit = row.get('lower_limit', None)
            
            # ç‰¹å¾´é‡æŠ½å‡º
            features = self.extract_all_features(
                sequence,
                upper_limit=upper_limit,
                lower_limit=lower_limit
            )
            
            enriched_features.append(features)
            
            if (idx + 1) % 1000 == 0:
                print(f"  Processed {idx + 1}/{len(df)} samples...")
        
        # ç‰¹å¾´é‡ã‚’DataFrameã«å¤‰æ›
        features_df = pd.DataFrame(enriched_features)
        
        # å…ƒã®DataFrameã¨çµåˆ
        enriched_df = pd.concat([df, features_df], axis=1)
        
        # ä¿å­˜
        enriched_df.to_csv(output_path, index=False, encoding='utf-8-sig')
        
        print(f"\nâœ“ Feature extraction completed")
        print(f"  Original features: {len(df.columns)}")
        print(f"  New features: {len(features_df.columns)}")
        print(f"  Total features: {len(enriched_df.columns)}")
        print(f"\nğŸ’¾ Saved to: {output_path}")
        
        # ç‰¹å¾´é‡ã®çµ±è¨ˆæƒ…å ±
        print("\nğŸ“Š Feature statistics:")
        print(features_df.describe())
        
        print("\n" + "="*70)
        print("âœ… å®Œäº†!")
        print("="*70)
        
        return enriched_df


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    engineer = FeatureEngineer()
    enriched_df = engineer.enrich_training_samples()
    
    # ãƒ†ã‚¹ãƒˆã‚µãƒ³ãƒ—ãƒ«ã«ã‚‚åŒã˜å‡¦ç†ã‚’é©ç”¨
    print("\n\nğŸ“‚ Processing test samples...")
    test_input = PROCESSED_DATA_DIR / "test_samples.csv"
    test_output = PROCESSED_DATA_DIR / "test_samples_enriched.csv"
    
    if test_input.exists():
        engineer.enrich_training_samples(
            input_path=test_input,
            output_path=test_output
        )
    else:
        print("âš  Test samples not found. Skipping.")


if __name__ == "__main__":
    main()
